{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seed for all devices (both CPU and CUDA)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "\n",
    "# Define paths to your data folders\n",
    "# Load labeled, validation, and test datasets\n",
    "train_data_dir = '/oci/train/'\n",
    "val_data_dir = '/oci/validation/'\n",
    "test_data_dir = '/oci/test/'\n",
    "\n",
    "# Example transformations (customize based on your requirements)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load your training, validation, and test datasets using ImageFolder\n",
    "train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "# Print the number of images in each dataset\n",
    "print(f\"Number of images in the training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in the validation set: {len(val_dataset)}\")\n",
    "print(f\"Number of images in the test set: {len(test_dataset)}\")\n",
    "\n",
    "# Create DataLoader for training, validation, and test sets\n",
    "batch_size = 8  # Adjust according to your needs\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your SimpleDenseNet model (as defined previously)\n",
    "class SimpleDenseNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleDenseNet, self).__init__()\n",
    "        self.model = timm.create_model('densenet201', pretrained=True)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate the custom DenseNet model\n",
    "num_classes = 2  # Binary classification\n",
    "model = SimpleDenseNet(num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your model, train_loader, val_loader, test_loader, criterion, and optimizer here\n",
    "\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Initialize EER and threshold variables\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "early_stopping_patience = 2\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            scores = torch.nn.functional.softmax(outputs, dim=1)[:, 1]\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_scores.extend(scores.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Check for NaN values in the arrays\n",
    "    if np.isnan(val_loss):\n",
    "        print(\"Error: NaN value encountered in validation loss. Skipping this epoch.\")\n",
    "        continue  # Skip to the next epoch\n",
    "    else:\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Validation loss didn't improve for {} epochs. Early stopping...\".format(early_stopping_patience))\n",
    "                break\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(all_labels, all_scores, pos_label=1)\n",
    "        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "        threshold = thresholds[np.nanargmin(np.abs(fpr - eer))]\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation EER: {eer * 100:.2f}%\")\n",
    "        print(f\"Validation EER Threshold: {threshold:.4f}\")\n",
    "\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        break  # Stop training if early stopping condition met\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "test_labels = []\n",
    "test_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        scores = torch.nn.functional.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_scores.extend(scores.cpu().numpy())\n",
    "\n",
    "# Calculate the HTER on the testing set using the EER threshold\n",
    "threshold_test = threshold  # Use the EER threshold from the validation set for testing\n",
    "predicted_labels_test = [1 if score > threshold_test else 0 for score in test_scores]\n",
    "\n",
    "false_acceptance_test = sum(1 for i in range(len(predicted_labels_test)) if predicted_labels_test[i] == 1 and test_labels[i] == 0)\n",
    "false_rejection_test = sum(1 for i in range(len(predicted_labels_test)) if predicted_labels_test[i] == 0 and test_labels[i] == 1)\n",
    "\n",
    "total_samples_test = len(test_labels)\n",
    "hter_test = ((false_acceptance_test + false_rejection_test) / (2 * total_samples_test)) * 100\n",
    "print(f\"HTER using EER threshold: {hter_test:.2f}%\")\n",
    "\n",
    "# Calculate AUC on the test set\n",
    "auc_test = roc_auc_score(test_labels, test_scores)\n",
    "print(f\"Area Under the ROC Curve (AUC) on the test set: {auc_test * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "pt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
